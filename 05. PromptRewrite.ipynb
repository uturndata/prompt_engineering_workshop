{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import TransformChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from rich.pretty import pprint\n",
    "\n",
    "# maybe use a cheaper model for the rewrite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs={\"temperature\": 0.99, 'max_tokens': 20000},\n",
    "    guardrails={\"guardrailIdentifier\": \"pparlr97o7gz\", \"guardrailVersion\": \"1\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unchanged_prompt = PromptTemplate(\n",
    "    input_variables=[\"prompt\"], \n",
    "    template=\"{prompt}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514aec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "act as an expert in prompt engineering who is skilled at \n",
    "getting the most useful responses possible from a generative AI model.\n",
    "\n",
    "rewrite the following to be a more effective prompt.\n",
    "the prompt should emphasize a succinct response.\n",
    "\n",
    "return only the text of the rewritten prompt, without a preamble.\n",
    "                                           \n",
    "{prompt}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ba899",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = PromptTemplate(\n",
    "    input_variables=[\"content\"], \n",
    "    template=\"{content}\"\n",
    ")\n",
    "\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"content\"], \n",
    "    output_variables=[\"content\"], \n",
    "    transform=lambda data: {'content': data['content'].content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    original = unchanged_prompt | model | StrOutputParser(),\n",
    "    rewrite = rewrite_prompt | model | transform_chain | mapper  | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"prompt\": \"is long distance space travel possible?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print('ORIGINAL:')\n",
    "print(response['original'])\n",
    "print('---------------------------------------')\n",
    "print('REWRITE:')\n",
    "print(response['rewrite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14aaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
